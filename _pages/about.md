---
layout: about
title: about
permalink: /
# description: >
#   <a href="https://c4dm.eecs.qmul.ac.uk/">C4DM</a> @ <a href="https://www.qmul.ac.uk/">QMUL</a>.
#   PhD Researcher.

profile:
  align: right
  image: prof_pic.jpg
  # address: >
  #   <p>ENG 408, School of EECS</p>
  #   <p>QMUL</p>
  #   <p>London E1 4NS</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
news: false  # includes a list of news items
social: true  # includes social icons at the bottom of the page
---

I am a PhD student in Artificial Intelligence and Music at [Queen Mary University of London](https://www.qmul.ac.uk).
I am researching applications of meta-learning to neural audio synthesis and deep psychoacoustic models of musical timbre.
I am very grateful to be funded by the [UKRI Centre for Doctoral Training in Artificial Intelligence and Music](https://www.aim.qmul.ac.uk/),
and am a member of the [Centre for Digital Music](https://c4dm.eecs.qmul.ac.uk/).

Previously, I was Music Lead at the award-winning AI-driven generative music startup [Jukedeck](https://www.linkedin.com/company/jukedeck/about/), and was a research intern with [ByteDance](https://www.bytedance.com/en/)'s Speech, Audio & Music Intelligence (SAMI) team. I also [make music](https://open.spotify.com/artist/73A1Xo6NzkbRB2EIw3dm6R).

I am particularly open to collaborations with musicians and artists looking to apply artificial intelligence to their auditory work, real-time/DSP engineers interested in turning neural audio synthesis research into usable tools, and researchers working on related topics.

You can contact me at *b.j.hayes (at) qmul.ac.uk*
